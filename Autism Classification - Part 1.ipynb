{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "attributes_train = ['question1', 'question2', 'question3', 'question4', 'question5', 'question6', 'question7', 'question8', 'question9', 'question10', 'question11', 'question12', 'question13', 'question14', 'question15', 'question16', 'question17', 'question18', 'question19', 'question20', 'question21', 'question22', 'question23', 'question24', 'question25', 'question26', 'question27', 'question28', 'question29', 'question30', 'diag']\n",
    "attributes_test = ['question1', 'question2', 'question3', 'question4', 'question5', 'question6', 'question7', 'question8', 'question9', 'question10', 'question11', 'question12', 'question13', 'question14', 'question15', 'question16', 'question17', 'question18', 'question19', 'question20', 'question21', 'question22', 'question23', 'question24', 'question25', 'question26', 'question27', 'question28', 'question29', 'question30', 'ASD']\n",
    "train, test = pd.read_csv('./Tariq-Wall-2018-PLOS-MEDICINE/datasets/primary_dataset.csv'), pd.read_csv('./Tariq-Wall-2018-PLOS-MEDICINE/datasets/validation_dataset.csv')\n",
    "train, test = train[attributes_train], test[attributes_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove bad data from train\n",
    "def remove_nan(data_frame):\n",
    "    question_stub = \"question\"\n",
    "    to_remove = []\n",
    "    for index in data_frame.index.tolist():\n",
    "        valid = True\n",
    "        row = data_frame.loc[index]\n",
    "        for j in range(1,31):\n",
    "            question = question_stub + str(j)\n",
    "            value = row[question]\n",
    "            if(value != value):\n",
    "                valid = False\n",
    "        if(not valid):\n",
    "            to_remove.append(index)\n",
    "    \n",
    "    return to_remove\n",
    "\n",
    "to_remove = remove_nan(train)\n",
    "train.drop(to_remove, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# upsample or downsample data\n",
    "def upsample(data_frame):\n",
    "    min_pop = data_frame.loc[data_frame['diag'] == 'non-asd']\n",
    "    maj_pop = data_frame.loc[data_frame['diag'] == 'asd']\n",
    "    sample_size = maj_pop.shape[0] - min_pop.shape[0]\n",
    "    \n",
    "    indices = min_pop.index.tolist()\n",
    "    \n",
    "    # sample minority population with replacement\n",
    "    sample = random.choices(population=indices, k=sample_size)\n",
    "    \n",
    "    return sample\n",
    "\n",
    "sample = upsample(train)\n",
    "\n",
    "for idx in sample: # hacky way to append to pandas dataframe without copying..\n",
    "    train.loc[train.index.max() + 1] = train.loc[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# populations equally represented now??\n",
    "assert(train.loc[train['diag'] == 'asd'].shape == train.loc[train['diag'] == 'non-asd'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train, data_test = train.values, test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature selection for 4, and 8 features\n",
    "LABEL_IDX = -1\n",
    "def is_single_class(data):\n",
    "    return len(np.unique(data[:,LABEL_IDX])) == 1\n",
    "\n",
    "def classify(data):\n",
    "    classes, counts = np.unique(data[:, LABEL_IDX], return_counts=True)\n",
    "    return int(classes[np.argmax(counts)] == 'asd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_single_class(data_train)\n",
    "classify(data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "def get_data_partitions(data, features=None):\n",
    "    \n",
    "    #all features\n",
    "    if(features == None):\n",
    "        features = np.arange(0, data.shape[1]-1)\n",
    "        \n",
    "    partitions = defaultdict(list)\n",
    "    for idx in range(0, data.shape[1]-1):\n",
    "        # one of selected features?\n",
    "        if(idx in features):\n",
    "            unique_scores = np.unique(data[:, idx])\n",
    "            for x in range(len(unique_scores)-1):\n",
    "                divide = np.mean(unique_scores[x:x+2])\n",
    "                partitions[idx].append(divide)\n",
    "        else:\n",
    "            continue\n",
    "        \n",
    "    \n",
    "    return partitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_partitions = get_data_partitions(data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def partition_data(data, question, score):\n",
    "    a,b = data[data[:, question] >= score], data[data[:, question] < score]\n",
    "    \n",
    "    return a,b\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b = partition_data(data_train, 0, .5)\n",
    "def get_entropy(data):\n",
    "    _, counts = np.unique(data[:, LABEL_IDX], return_counts=True)\n",
    "    p_i = counts / sum(counts)\n",
    "    return (p_i * -np.log2(p_i)).sum() # entropy sum(p_i * -log2(p_i))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_total_entropy(a, b):\n",
    "    n = a.shape[0] + b.shape[0]\n",
    "    p_a, p_b = a.shape[0] / n, b.shape[0] / n\n",
    "    entropy_a, entropy_b = get_entropy(a), get_entropy(b)\n",
    "    return p_a*entropy_a + p_b*entropy_b\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9180501456009732"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_total_entropy(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lowest_entropy_partition(data, data_partitions):\n",
    "    \n",
    "    lowest = np.inf\n",
    "    split_question = None\n",
    "    split_score = None\n",
    "    \n",
    "    for question in data_partitions:\n",
    "        cutoffs = data_partitions[question]\n",
    "        for score in cutoffs:\n",
    "            a,b = partition_data(data, question, score)\n",
    "            entropy = get_total_entropy(a,b)\n",
    "            if(entropy < lowest):\n",
    "                lowest = entropy\n",
    "                split_question = question\n",
    "                split_score = score\n",
    "    \n",
    "    return split_question, split_score, lowest\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_question, split_score, lowest_entropy = lowest_entropy_partition(data_train, data_partitions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24, 2.5, 0.615043579752023)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_question, split_score, lowest_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Queue(object):\n",
    "    def __init__(self):\n",
    "        self.queue = []\n",
    "    \n",
    "    def enqueue(self, item):\n",
    "        self.queue.append(item)\n",
    "    \n",
    "    def dequeue(self):\n",
    "        self.queue[0], self.queue[-1] = self.queue[-1], self.queue[0]\n",
    "        \n",
    "        return self.queue.pop()\n",
    "    \n",
    "    def peek(self):\n",
    "        if(not self.is_empty()):\n",
    "            return self.queue[0]\n",
    "    \n",
    "    def is_empty(self):\n",
    "        return len(self.queue) == 0\n",
    "    \n",
    "    def size(self):\n",
    "        return len(self.queue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_k_lowest_features(data, k):\n",
    "    features = []\n",
    "    q = Queue()\n",
    "    q.enqueue(data)\n",
    "    while(len(features) < k):\n",
    "        size = q.size()\n",
    "        for x in range(size):\n",
    "            data = q.dequeue()\n",
    "            \n",
    "            data_partitions = get_data_partitions(data)\n",
    "            \n",
    "            feature, value, _ = lowest_entropy_partition(data, data_partitions)\n",
    "            if(feature != None):\n",
    "                features.append(feature)\n",
    "                a, b = partition_data(data, feature, value)\n",
    "                q.enqueue(a)\n",
    "                q.enqueue(b)\n",
    "    \n",
    "    return features[0:k+1]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_8 = select_k_lowest_features(data_train, k=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_4 = select_k_lowest_features(data_train, k=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TreeNode(object):\n",
    "    def __init__(self, feature, value):\n",
    "        self.question = \"%s >= %0.2f\" % (feature, value)\n",
    "        self.feature = feature\n",
    "        self.value = value\n",
    "        self.yes = None\n",
    "        self.no = None\n",
    "    \n",
    "    def __str__(self):\n",
    "        return self.question\n",
    "        \n",
    "def get_decision_tree(data, features=None):\n",
    "    if(is_single_class(data)):\n",
    "        return classify(data)\n",
    "    else:\n",
    "        # get question, and cutoff with lowest overall entropy\n",
    "        data_partitions = get_data_partitions(data, features)\n",
    "        split_question, split_value, lowest_entropy = lowest_entropy_partition(data, data_partitions)\n",
    "        node = TreeNode(split_question, split_value)\n",
    "        a, b = partition_data(data, split_question, split_value)\n",
    "        \n",
    "        # recurse on left, and right subtrees..\n",
    "        node.yes = get_decision_tree(a, features)\n",
    "        node.no = get_decision_tree(b, features)\n",
    "        \n",
    "        return node\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_all = get_decision_tree(data_train)\n",
    "#tree_4 = get_decision_tree(data_train, features=features_4)\n",
    "#tree_8 = get_decision_tree(data_train, features=features_8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bfs(root):\n",
    "    q = Queue()\n",
    "    \n",
    "    q.enqueue(root)\n",
    "    while(not q.is_empty()):\n",
    "        size = q.size()\n",
    "        \n",
    "        # process that lvl\n",
    "        for x in range(size):\n",
    "            node = q.dequeue()\n",
    "            print(node, end='\\t\\t')\n",
    "            # enqueue children if not classification\n",
    "            if(type(node) != int):\n",
    "                q.enqueue(node.yes)\n",
    "                q.enqueue(node.no)\n",
    "            else:\n",
    "                continue\n",
    "        # next level please..\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24 >= 2.50\t\t\n",
      "10 >= 2.50\t\t9 >= 1.50\t\t\n",
      "3 >= 2.50\t\t19 >= 2.50\t\t0\t\t10 >= 5.00\t\t\n",
      "20 >= 1.50\t\t0\t\t0\t\t8 >= 2.50\t\t1 >= 1.50\t\t5 >= 5.50\t\t\n",
      "7 >= 1.50\t\t24 >= 1.50\t\t21 >= 1.50\t\t1 >= 0.50\t\t0\t\t3 >= 0.50\t\t0\t\t0\t\t\n",
      "1\t\t18 >= 0.50\t\t1\t\t20 >= 0.50\t\t0\t\t0\t\t20 >= 5.00\t\t5 >= 0.50\t\t1\t\t1\t\t\n",
      "0\t\t25 >= 0.50\t\t1\t\t12 >= 5.50\t\t0\t\t7 >= 0.50\t\t0\t\t1\t\t\n",
      "0\t\t25 >= 1.50\t\t1 >= 2.50\t\t0\t\t1\t\t0 >= 0.50\t\t\n",
      "27 >= 2.50\t\t0\t\t21 >= 1.50\t\t0\t\t0 >= 0.50\t\t8 >= 0.50\t\t\n",
      "0\t\t0\t\t1\t\t1\t\t1\t\t1\t\t6 >= 0.50\t\t1\t\t\n",
      "14 >= 2.50\t\t15 >= 2.50\t\t\n",
      "17 >= 5.50\t\t25 >= 0.50\t\t1 >= 2.50\t\t0\t\t\n",
      "21 >= 1.50\t\t1\t\t5 >= 2.00\t\t8 >= 1.50\t\t29 >= 0.50\t\t17 >= 1.50\t\t\n",
      "1\t\t1\t\t0\t\t0\t\t15 >= 2.50\t\t0\t\t0\t\t1 >= 1.50\t\t1\t\t1\t\t\n",
      "0\t\t20 >= 5.00\t\t5 >= 1.50\t\t1\t\t\n",
      "9 >= 6.00\t\t7 >= 5.00\t\t1\t\t0\t\t\n",
      "1\t\t11 >= 0.50\t\t2 >= 0.50\t\t0\t\t\n",
      "1\t\t0\t\t1\t\t15 >= 1.50\t\t\n",
      "0 >= 0.50\t\t1\t\t\n",
      "5 >= 0.50\t\t1\t\t\n",
      "1\t\t5 >= 2.50\t\t\n",
      "1\t\t0\t\t\n"
     ]
    }
   ],
   "source": [
    "bfs(tree_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_obs(root, obs):\n",
    "    cur = root\n",
    "    while(type(cur) != int):\n",
    "        #print(cur)\n",
    "        feature, value = cur.feature, cur.value\n",
    "        direction = obs[feature] >= value\n",
    "        if(direction == True):\n",
    "            #print(\"Yes\")\n",
    "            cur = cur.yes\n",
    "        else:\n",
    "            #print(\"No\")\n",
    "            cur = cur.no\n",
    "    \n",
    "    return cur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_data(root, data_test):\n",
    "    mapping = {'asd': 1, 'non-asd': 0, 0:0, 1:1}\n",
    "    correct = 0\n",
    "    for obs in data_test:\n",
    "        pred = classify_obs(root, obs)\n",
    "        actual = mapping[obs[-1]]\n",
    "        if(pred == actual):\n",
    "            correct += 1\n",
    "    \n",
    "    print(\"Accuracy: %0.2f percent\" %((correct / len(data_test))*100))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 100.00 percent\n",
      "Accuracy: 79.34 percent\n"
     ]
    }
   ],
   "source": [
    "validate_data(tree_all, data_train)\n",
    "validate_data(tree_all, data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'validate_data(tree_4, data_train)\\nvalidate_data(tree_4, data_test)'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''validate_data(tree_4, data_train)\n",
    "validate_data(tree_4, data_test)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'validate_data(tree_8, data_train)\\nvalidate_data(tree_8, data_test)'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''validate_data(tree_8, data_train)\n",
    "validate_data(tree_8, data_test)'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
